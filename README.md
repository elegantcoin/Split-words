# fenci

<p align="center">
    <a href="https://github.com/elegantcoin/fenci"><img src="https://img.shields.io/badge/status-updating-brightgreen.svg"></a>
    <a href="https://github.com/python/cpython"><img src="https://img.shields.io/badge/Python-3.7-FF1493.svg"></a>
    <a href="https://github.com/elegantcoin/fenci"><img src="https://img.shields.io/badge/platform-Windows%7CLinux%7CmacOS-660066.svg"></a>
    <a href="https://opensource.org/licenses/mit-license.php"><img src="https://badges.frapsoft.com/os/mit/mit.svg"></a>
    <a href="https://github.com/elegantcoin/fenci/stargazers"><img src="https://img.shields.io/github/stars/elegantcoin/fenci.svg?logo=github"></a>
    <a href="https://github.com/elegantcoin/fenci/network/members"><img src="https://img.shields.io/github/forks/elegantcoin/fenci.svg?color=blue&logo=github"></a>
    <a href="https://www.python.org/"><img src="https://upload.wikimedia.org/wikipedia/commons/c/c3/Python-logo-notext.svg" align="right" height="48" width="48" ></a>
</p>
<br />

inspired by [分词打标](http://www.gooseeker.com/res/softdetail_13.html), A splitting Chinese words and counting their frequence method is presentated. Since the original system is poorly performed, stopwords are used and English words are delt with correctly.

results should be:
![](http://www.gooseeker.com/res/resimg.html?type=0&name=tagtool2-6.png)
![](http://www.gooseeker.com/res/resimg.html?type=0&name=tagtool2-4.png)

  # - input：
  - [All.csv](https://github.com/elegantcoin/fenci/blob/master/All.csv) words need to be split.
  - [stopwords.txt](https://github.com/elegantcoin/fenci/blob/master/stopwords.txt) stopwords used(both English and Chinese).
  
    # - main file：
  - [All.csv](https://github.com/elegantcoin/fenci/blob/master/All.csv) words need to be split.
  - [stopwords.txt](https://github.com/elegantcoin/fenci/blob/master/stopwords.txt) stopwords used(both English and Chinese).
  
    # - output：
  - [All.csv](https://github.com/elegantcoin/fenci/blob/master/All.csv) words need to be split.
  - [stopwords.txt](https://github.com/elegantcoin/fenci/blob/master/stopwords.txt) stopwords used(both English and Chinese).

  # - 思考：
  - cloudword?
  - 关键信息成组
  - 舆情分析
